---
title: "Analysis of systems’ performance in natural language processing competitions"
author: "Sergio M. Nava Muñoz"
institute:  "CIMAT / INFOTEC"
date: "Oct 2024"
format: 
  revealjs:
    slide-number: true
    theme: "black"
    highlight: "pygments"
toc: TRUE
---


# Introduction

---

### Challenge 

![Challenge](figs/Competencia.png)

## Challenge Restrictions


- Comparison of multiple participants (systems)
- Selected performance metrics
- A test dataset of fixed size \( $n$ \)
- A limited number of submissions per participant
- The Reference (Gold Standard) is known just for the organizers
- The objective can be to choose the best or to rank the participants



## Results for VaxxStance Close track - contextual {.smaller}


:::: {.columns}

::: {.column width="70%"}
| Obs  | Gold Standard | WordUp.01 | ...   | SQYQP.01 |
|------|---------------|-----------|-------|----------|
| 1    | favor         | favor     | ...   | favor    |
| 2    | favor         | favor     | ...   | none     |
| 3    | against       | none      | ...   | against  |
| 4    | none          | none      | ...   | none     |
| ...  | ...           | ...       | ...   | ...      |
| \(n_{test}\) | none    | favor     | ...   | against  |

*Table: Results for VaxxStance Close track - contextual.*
:::

::: {.column width="25%"  .fragment }
| System              | Basque  |
|---------------------|---------|
| WordUp.01           | 0.5734  |
| WordUp.02           | 0.5465  |
| MultiAztertest.01   | 0.5024  |
| SQYQP.01            | 0.4256  |
| MultiAztertest.02   | 0.3428  |

*Table: Results using Macro-averaged F1 Score for "favor" and "against".*
:::

::::

# Proposed methodology

---

## Comparison of Classifiers {.smaller}

Results Table for Basque and Spanish

::: {.small-table}
|                | LCI    | Mean   | UCI    |        |                | LCI    | Mean   | UCI    |
|----------------|--------|--------|--------|--------|----------------|--------|--------|--------|
| **Basque**     |        |        |        |        | **Spanish**    |        |        |        |
| **WordUp.01**  | 0.5031 | 0.5716 | 0.6401 |        | **WordUp.02**  | 0.7734 | 0.8086 | 0.8437 |
| WordUp.02      | 0.4751 | 0.5444 | 0.6138 |        | WordUp.01      | 0.7537 | 0.7899 | 0.8261 |
| **MultiAztertest.01** | 0.4287 | 0.5007 | 0.5726 |        | **MultiAztertest.01** | 0.6987 | 0.7400 | 0.7814 |
| SQYQP.01       | 0.3497 | 0.4237 | 0.4976 |        | SQYQP.01       | 0.6310 | 0.6730 | 0.7149 |
| **MultiAztertest.02** | 0.2664 | 0.3402 | 0.4139 |        | **MultiAztertest.02** | 0.5945 | 0.6391 | 0.6837 |
:::

![Independent Samples](figs/ordenado2.png){width="600" height="300"}

---

##   {.smaller}

Results Table for Basque (WordUp.01) and Spanish (WordUp.02)

::: {.small-table}
|                | LCI    | Mean   | UCI    |        |                | LCI    | Mean   | UCI    |
|----------------|--------|--------|--------|--------|----------------|--------|--------|--------|
| **Basque (WordUp.01)** |        |        |        |        | **Spanish (WordUp.02)** |        |        |        |
| **WordUp.02**  | -0.0371| 0.0269 | 0.0910 |        | **WordUp.01**  | -0.0120| 0.0184 | 0.0488 |
| MultiAztertest.01 | -0.0152| 0.0713 | 0.1578 |        | MultiAztertest.01 | 0.0211 | 0.0680 | 0.1149 |
| **SQYQP.01**   | 0.0543 | 0.1485 | 0.2427 |        | **SQYQP.01**   | 0.0877 | 0.1351 | 0.1825 |
| MultiAztertest.02 | 0.1405 | 0.2314 | 0.3222 |        | MultiAztertest.02 | 0.1165 | 0.1687 | 0.2210 |
:::

![Paired Samples](figs/mejorordenado2.png){width="600" height="300"}

## Hypothesis Testing {.smaller}

*Differences of F₁ score for Basque*

*Note: † p<.1, * p<.05, ** p<.1, and *** p<.001.*

::: {.small-table}
|                     | WordUp.01  | WordUp.02  | MultiAztertest.01 | SQYQP.01  |
|---------------------|------------|------------|-------------------|-----------|
| **WordUp.02**        | 0.027      |            |                   |           |
| MultiAztertest.01    | 0.071 †    | 0.044      |                   |           |
| **SQYQP.01**         | 0.148 ***  | 0.121 **   | 0.077 *           |           |
| MultiAztertest.02    | 0.231 ***  | 0.204 ***  | 0.160 ***         | 0.083 *   |
:::

![histogram of differences ](figs/histogram2.png){width="600" height="250"}

## Multiple Testing

### Risk of Multiple Testing

::: {.callout-note}
Multiple hypothesis testing increases the risk of Type I errors—the false rejection of a true null hypothesis.
:::

### Correction Methods

1. **Bonferroni correction**: Divides the significance level by the number of comparisons.
2. **Holm's step-down procedure**: Adjusts p-values sequentially.
3. **Benjamini-Hochberg (BH) procedure**: Controls the false discovery rate (FDR).

---

## {.smaller}

**Estimated p-values for F1 difference **

*Table: Estimated p-value for the F₁ difference without adjustment and with Bonferroni, FDR, Holm, and BH adjustments.*

::: {.small-table}
|                   |                   | Difference | p-value  | Bonferroni | Holm     | BH       |
|-------------------|-------------------|------------|----------|------------|----------|----------|
| WordUp.01         | WordUp.02          | 0.027      | **0.2030** | **0.8120** | **0.2030** | **0.2030** |
| WordUp.01         | MultiAztertest.01  | 0.071      | **0.0551** | **0.2204** | **0.1102** | **0.0735** |
| WordUp.01         | SQYQP.01           | 0.148      | 0.0012   | 0.0048     | 0.0036   | 0.0024   |
| WordUp.01         | MultiAztertest.02  | 0.231      | 0.0000   | 0.0000     | 0.0000   | 0.0000   |
| WordUp.02         | MultiAztertest.01  | 0.044      | **0.1490** | **0.4470** | **0.1490** | **0.1490** |
| WordUp.02         | SQYQP.01           | 0.121      | 0.0039   | 0.0117     | 0.0078   | 0.0058   |
| WordUp.02         | MultiAztertest.02  | 0.204      | 0.0000   | 0.0000     | 0.0000   | 0.0000   |
| MultiAztertest.01 | SQYQP.01           | 0.077      | 0.0330   | **0.0660** | 0.0330   | 0.0330   |
| MultiAztertest.01 | MultiAztertest.02  | 0.160      | 0.0003   | 0.0006     | 0.0006   | 0.0006   |
| SQYQP.01          | MultiAztertest.02  | 0.083      | 0.0427   | 0.0427     | 0.0427   | 0.0427   |
:::

## Analysis of NLP Competitions  {.smaller .scrollable transition="slide"}



:::{.small-table}
| Competition        | Subtask / Language                                       | Metric Used                              | Data Considered                          |
|--------------------|----------------------------------------------------------|------------------------------------------|------------------------------------------|
| MEX-A3T 2019       | Author Profiling (Spanish, text and images)               | Macro-averaged F1 Score                  | All participants                         |
|                    | Aggressiveness Detection (Spanish)                       | F1 Score                                 | All participants                         |
| TASS 2020          | General Polarity (Spanish)                               | Macro-averaged F1 Score                  | All participants (Best Runs)             |
| **VaxxStance 2021**| **Stance Detection (Basque, Spanish)**                   | **Macro-averaged F1 Score for "favor" and "against"** | **All participants** |
| EXIST 2021         | Sexism Identification (English, Spanish)                 | Accuracy                                 | Top 10 for each language (Best Runs)     |
|                    | Sexism Categorization (English, Spanish)                 | Macro-averaged F1 Score                  | Top 10 for each language (Best Runs)     |
| DETOXIS 2021       | Toxicity Detection (Spanish)                             | F1 Score                                 | All participants (Best Runs)             |
| MeOffendEs 2021    | Offensive Language Identification (Mexican Spanish)      | F1 Score (offensive class)               | All participants (Best Runs)             |
| REST-MEX 2021      | Recommendation System (Mexican Spanish)                  | MAE                                      | All participants (baseline)              |
|                    | Sentiment Analysis (Mexican Spanish)                     | MAE                                      | All participants (baseline)              |
| REST-MEX 2022      | Sentiment Analysis (Mexican Spanish)                     | $Measure_S$                                | All participants (majority class)        |
|                    | Epidemiological Semaphore (Mexican Spanish)              | $Measure_C$                                | All participants (majority class)        |
| PAR-MEX 2022       | Paraphrase Identification (Mexican Spanish)              | F1 Score                                 | All participants (Best Runs)             |
:::


*Table: Metrics and data considered across various competitions.*

## Results for the Various Challenges {.smaller .scrollable transition="slide"}


*Table: Results for the Various Challenges.*

:::{.small-table}
| Challenge          | DETOXIS 2021 | PAR-MEX 2022 | MeOffendEs 2021 | MEX-A3T 2019 (Agg) | MEX-A3T 2019 (author profiling) |
|--------------------|--------------|--------------|-----------------|-------------------|--------------------------------|
| **Task**           | Toxicity detection | Paraphrase Identification | Non-contextual | Aggressiveness Detection | Author Profiling |
| **Metric**         | F1 score     | F1 score     | F1 score        | F1 score          | Macro-averaged F1 score       |
| **$n$**            | 891          | 2821         | 2182            | 3156              | 1500                          |
| **$m$**            | 31           | 8            | 10              | 25                | 4                             |
| **Ties w/ win.**   | 0/3/0/0      | 1/1/1/1      | 1/2/2/1         | 3/7/4/3           | 1/1/1/1                       |
| **Poss. compars.** | 465          | 28           | 45              | 300               | 6                             |
| **none/Bonf.**     | 80/135       | 6/6          | 7/9             | 70/91             | 2/2                           |
| **Holm/BH**        | 112/85       | 6/6          | 8/7             | 80/63             | 2/2                           |
| **$|win.-med|$**   | 0.223        | 0.061        | 0.078           | 0.098             | 0.164                         |
| **$CV$**           | 42.600       | 4.722        | 16.070          | 19.620            | 46.491                        |
| **PPI**            | 35.390       | 5.758        | 28.46           | 52.038            | 42.581                        |
:::


