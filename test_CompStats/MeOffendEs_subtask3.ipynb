{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGizC3XikMtk"
   },
   "source": [
    "<p><img alt=\"Colaboratory logo\" height=\"50px\" src=\"https://github.com/INGEOTEC/text_models/raw/master/docs/source/ingeotec.png\" align=\"left\" hspace=\"10px\" vspace=\"0px\" /></p>\n",
    "\n",
    "# CompStats\n",
    "## Quickstart Guide\n",
    "\n",
    "### <http://compstats.readthedocs.org>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-QV6DJYaQjg"
   },
   "source": [
    "## Installing CompStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ISeelAVIJc59"
   },
   "outputs": [],
   "source": [
    "# !python -m pip uninstall CompStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_4WTIJx5H9ii"
   },
   "outputs": [],
   "source": [
    "# %pip install -U git+https://github.com/INGEOTEC/CompStats@develop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sFWAgM0H3La"
   },
   "source": [
    "First, we need to install CompStats. This can be quickly done through pip, the Python package manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k2UzLxhkkMtp",
    "outputId": "dbadd757-1706-49ed-b866-539afbe92f71"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import CompStats\n",
    "except ImportError:\n",
    "    !pip install Compstats\n",
    "    # !pip install -U git+https://github.com/INGEOTEC/CompStats@develop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqJKAfenkMtr"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifWsyR9mH7-o"
   },
   "source": [
    "After installing `CompStats`, we must import the necessary libraries for our analysis. `CompStats` relies on several Python libraries for data analysis and scientific computing.\n",
    "\n",
    "The first line of the following code loads two functions from the `CompStats` library. The `performance` function is used to calculate and analyze the performance of machine learning models. On the other hand, the `plot_performance` function visualizes the performance metrics calculated by `performance`, such as accuracy or F1 score, along with confidence intervals to help understand the variability and reliability of the performance metrics.\n",
    "\n",
    "The second line imports two functions: `difference` and `plot_difference`; `difference` assesses the differences in performance between models in comparison to the best system, and `plot_difference` visually represents these differences relative to the best system.\n",
    "\n",
    "The third line imports two functions: `all_differences` and `difference_p_value`. `all_differences` evaluates the differences in performance between all models, and `difference_p_value` estimates the p-value of the hypothesis that the difference is significantly greater than zero.\n",
    "\n",
    "The fourth line imports the function `multipletests`that is used for adjusting p-values when multiple hypothesis tests are performed, to control for the false discovery rate or family-wise error rate.\n",
    "\n",
    "The rest of the lines load commonly used Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rUVyzgMokMts"
   },
   "outputs": [],
   "source": [
    "from CompStats import performance, plot_performance\n",
    "from CompStats import difference, plot_difference\n",
    "from CompStats import all_differences, difference_p_value\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWcPnzA2HI-Y"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKbW9vf-IASa"
   },
   "source": [
    "Once we have set up our environment, we can explore what CompStats offers. Let's begin with a basic example of how to use CompStats for a simple statistical analysis.\n",
    "\n",
    "To illustrate the use of CompStats, we will use a dataset included in the CompStats package. The path of the dataset is found with the following instructions. The variable `DATA` contains the path as shown below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "8TGr5Jh6HIPR",
    "outputId": "b16c1843-a520-4b42-b653-84aee799f963"
   },
   "outputs": [],
   "source": [
    "# from CompStats.tests.test_performance import DATA\n",
    "DATA = 'MeOffendEs_subtask3.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seBE-afbkMts"
   },
   "source": [
    "`DATA` contains the information to compare six systems for a multiclass classification task. The next instruction loads the data into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WFo5qGVGI5fg"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnOx0jOAJw6H"
   },
   "source": [
    "The first five rows of `df` are shown below. It can be observed that the first column contains the gold standard, identified with `y`, and the rest of the columns are the predictions performed by different systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "PxDOXB8QJ2yT",
    "outputId": "08dad3e6-bdf9-4c72-848f-5576ccd383cc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>aomar</th>\n",
       "      <th>CEN-Amrita</th>\n",
       "      <th>CIC-IPN</th>\n",
       "      <th>CIMAT-GTO</th>\n",
       "      <th>CIMAT-MTY-GTO</th>\n",
       "      <th>DCCD-INFOTEC</th>\n",
       "      <th>NLP-CIC</th>\n",
       "      <th>Timen</th>\n",
       "      <th>UMUTeam</th>\n",
       "      <th>xjywing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2182</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y  aomar  CEN-Amrita  CIC-IPN  CIMAT-GTO  CIMAT-MTY-GTO  DCCD-INFOTEC  \\\n",
       "2178  0      1           1        1          1              1             0   \n",
       "2179  1      1           1        0          1              1             1   \n",
       "2180  0      1           1        0          0              0             0   \n",
       "2181  1      1           1        0          1              1             1   \n",
       "2182  0      1           1        0          1              0             0   \n",
       "\n",
       "      NLP-CIC  Timen  UMUTeam  xjywing  \n",
       "2178        1      1        0        1  \n",
       "2179        1      0        1        1  \n",
       "2180        0      0        0        1  \n",
       "2181        1      0        0        1  \n",
       "2182        0      0        0        1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>aomar</th>\n",
       "      <th>CEN-Amrita</th>\n",
       "      <th>CIC-IPN</th>\n",
       "      <th>CIMAT-GTO</th>\n",
       "      <th>CIMAT-MTY-GTO</th>\n",
       "      <th>DCCD-INFOTEC</th>\n",
       "      <th>NLP-CIC</th>\n",
       "      <th>Timen</th>\n",
       "      <th>UMUTeam</th>\n",
       "      <th>xjywing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2182</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2183 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y  aomar  CEN-Amrita  CIC-IPN  CIMAT-GTO  CIMAT-MTY-GTO  DCCD-INFOTEC  \\\n",
       "0     0      1           1        0          0              0             0   \n",
       "1     0      1           1        1          0              0             1   \n",
       "2     1      1           1        1          0              1             1   \n",
       "3     0      1           1        0          0              0             0   \n",
       "4     1      1           1        1          1              1             1   \n",
       "...  ..    ...         ...      ...        ...            ...           ...   \n",
       "2178  0      1           1        1          1              1             0   \n",
       "2179  1      1           1        0          1              1             1   \n",
       "2180  0      1           1        0          0              0             0   \n",
       "2181  1      1           1        0          1              1             1   \n",
       "2182  0      1           1        0          1              0             0   \n",
       "\n",
       "      NLP-CIC  Timen  UMUTeam  xjywing  \n",
       "0           0      0        0        1  \n",
       "1           0      0        0        1  \n",
       "2           0      1        1        1  \n",
       "3           0      0        0        1  \n",
       "4           1      1        1        1  \n",
       "...       ...    ...      ...      ...  \n",
       "2178        1      1        0        1  \n",
       "2179        1      0        1        1  \n",
       "2180        0      0        0        1  \n",
       "2181        1      0        0        1  \n",
       "2182        0      0        0        1  \n",
       "\n",
       "[2183 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqI3FxmCI_pM"
   },
   "source": [
    "# Performance Anaylisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JR1B0lg4K85m"
   },
   "source": [
    "Let us start with the performance analysis of the different systems. The performance metric used is the weighted average F1 score. This performance is coded in the variable `score` as observed in the next instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IXHA4HRkLA9q"
   },
   "outputs": [],
   "source": [
    "score = lambda y, hy: f1_score(y, hy, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYCMtk-1LZtL"
   },
   "source": [
    "The next step is to compute the performance on the bootstrap samples; this is done with the function `performance`. The function has a few parameters; one is the `score`, which receives the metric used to measure the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-96k0EbaLadL",
    "outputId": "cba38610-383b-402e-e8e2-f0fcdea5908e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [01:37<00:00,  8.84s/it]\n"
     ]
    }
   ],
   "source": [
    "perf = performance(df, score=score,num_samples=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEfBLwenQpND"
   },
   "source": [
    "`perf` is an instance of `StatisticSamples`, the bootstrap samples can be seen on the property `calls`. The first five bootstrap samples of the performance of INGEOTEC are shown below. -- It verifies that the key is in the dictionary in case the dataset has been changed. --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IrbRfFuCQsGf",
    "outputId": "995bf6f7-02d8-4526-de25-4e56151d7f3b"
   },
   "outputs": [],
   "source": [
    "if 'DCCD-INFOTEC' in perf.calls:\n",
    "  print(f\"{perf.calls['DCCD-INFOTEC'][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaUGXqEVJE6A"
   },
   "source": [
    "The performance of the systems, along with their confidence intervals, can be seen using the next instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 506
    },
    "id": "djiadR9dkMts",
    "outputId": "fbd0675c-0933-4d6e-e142-633394526b61"
   },
   "outputs": [],
   "source": [
    "face_grid = plot_performance(perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBmUNHXWR2pL"
   },
   "source": [
    "It can be observed that the best system is INGEOTEC. Although the confidence intervals provide information that helps to assess the difference in the performance of the systems, in this case, the intervals intersect. Therefore, one needs another statistical tool to determine if the difference in performance is significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJ1gAxzkkMts"
   },
   "source": [
    "# Performance Comparison against the Winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peFwDTsNdRiz"
   },
   "source": [
    "The difference in their performance compared to the best-performing system can be used to compare the algorithms analyzed. The function `difference` computes the difference as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "0FXWINpdkMtt"
   },
   "outputs": [],
   "source": [
    "diff = difference(perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2p_ppDE9dV0F"
   },
   "source": [
    "`diff` is an instance of `StatisticSamples`; one can find the best system on the property `info`, as the following instruction shows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7oz3wbr6dr_m",
    "outputId": "a4b5e252-dcbe-4345-c5e5-e84acd3edce7"
   },
   "outputs": [],
   "source": [
    "diff.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iD_jAdwmd5QZ"
   },
   "source": [
    "The difference in performance can be visualized with the following instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "id": "obO7DOUWdW52",
    "outputId": "38b7de59-4aea-43b7-d3dc-eae94c6f19d6"
   },
   "outputs": [],
   "source": [
    "face_grid_diff = plot_difference(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHlFz543kMtt"
   },
   "source": [
    "From the performance graphs, for this example, we can observe that the ranking is *INGEOTEC*, *BoW*, *StackBoW*, *BoW (Corpus)*, *Dense*, *Bow (Class Weight)*. Hence, in the last graph, we analyze the performance difference against the winner (INGEOTEC). From this graph, we can conclude that *BoW* and *StackBoW*, might perform similarly to INGEOTEC.\n",
    "\n",
    "Should we test the hypothesis of equality versus difference, considering that one system outperforms the other in the test? To address this question, we compare the performance of two systems, $A$ and $B$, to determine whether $A$ is superior to $B$ in a larger data population, represented as $\\theta_A > \\theta_B$. We can estimate the p-value associated with the hypothesis test $H_0: \\theta_A \\le \\theta_B$ vs $H_1: \\theta_A > \\theta_B$ given the data, equivalently $H_0: \\theta_A< -  \\theta_B\\le 0$ vs $H_1: \\theta_A - \\theta_B > 0$. The p-values for these differences can be estimated using the following instruction, comparing them against the winner (INGEOTEC) to determine the probability that $a$ (INGEOTEC) is better than $b$.\n",
    "\n",
    "The `difference_p_value` function estimates the p-value for each difference in comparison to the best system, as illustrated below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "83DAxZ18kMtt"
   },
   "outputs": [],
   "source": [
    "p_values = difference_p_value(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEEPzr4l2BMn"
   },
   "source": [
    "For a given $\\alpha$ level, p-values smaller than $\\alpha$  are significant, meaning the observed difference is unlikely to be due to chance. An $\\alpha$ level of 0.05 is commonly used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2VtUMvS0Z4k",
    "outputId": "6a3cf917-98da-46ed-a103-4faf13725e53"
   },
   "outputs": [],
   "source": [
    "p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = multipletests(list(p_values.values()), method='bonferroni')\n",
    "p_valuesC = dict(zip(p_values.keys(),result[1]))\n",
    "p_valuesC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rt21qMcDkMtu"
   },
   "source": [
    "# Performance comparison between all models\n",
    "\n",
    "Similarly, the differences for each pair of variables between all models can be estimated using the function `all_differences`, as illustrated in the following instructions. This approach allows for a comprehensive analysis of how each model compares to the others, providing a statistical basis to understand the significance of performance variations among them. This method extends the comparative analysis, offering a detailed view of the competitive landscape of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "6ehkDIH_kMtu"
   },
   "outputs": [],
   "source": [
    "all_diff = all_differences(perf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_diff.calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promedios = {key: sum(value) / len(value) for key, value in all_diff.calls.items()}\n",
    "promedios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CC2hR4w_4IzC"
   },
   "source": [
    "Once again, we use the function `difference_p_value` to estimate the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "x2vlIMNc3h5W"
   },
   "outputs": [],
   "source": [
    "p_values = difference_p_value(all_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "192xc-_24chZ"
   },
   "source": [
    "And we can analyze from all pairs of systems individually which ones have significantly different performances by comparing their p-value with $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l5hRhylS3jh2",
    "outputId": "b06cbf00-2d24-4714-e749-6210b2d96001"
   },
   "outputs": [],
   "source": [
    "p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: round(v, 3) for k, v in p_values.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NS3RHI9SkMtu"
   },
   "source": [
    "When conducting numerous comparisons or hypothesis tests on a dataset, the risk of incurring Type I errors (incorrectly dismissing a valid null hypothesis) increases. This happens because more tests performed increase the probability of randomly identifying statistically significant outcomes. Implementing adjustments for multiple comparisons is critical for several reasons: (1) To manage the risk of Type I Error, (2) To prevent erroneous conclusions, and (3) To uphold the integrity of the research.\n",
    "\n",
    "The following code illustrates the effect of these methods for multiple comparison corrections. The function `multipletests` makes the p-value correction by selecting the parameter `method`. In this example, the Bonferroni correction method is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "V1J_cqfdkMtu"
   },
   "outputs": [],
   "source": [
    "result = multipletests(list(p_values.values()), method='bonferroni')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2myRaBo6mPf"
   },
   "source": [
    "`result` is an array; next, we convert it back into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "MSaGBndz6G6t"
   },
   "outputs": [],
   "source": [
    "p_valuesC = dict(zip(p_values.keys(),result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FY-9W45Q7nId"
   },
   "source": [
    "And we can analyze from all pairs of systems simunstally which ones have significantly different performances by comparing their p-value with $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SKiKx3GU6IlN",
    "outputId": "94dd212d-dcae-4ec3-92f0-7397f5bd91a7"
   },
   "outputs": [],
   "source": [
    "p_valuesC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# assume p_values is a dictionary with p-values as values\n",
    "p_values_list = list(p_values.values())\n",
    "\n",
    "# define the correction methods to apply\n",
    "methods = ['bonferroni', 'holm', 'fdr_bh']\n",
    "\n",
    "# create a dictionary to store the corrected p-values\n",
    "corrected_pvalues = {}\n",
    "\n",
    "# apply each correction method and store the results\n",
    "for method in methods:\n",
    "    result = multipletests(p_values_list, method=method)\n",
    "    p_valuesC = dict(zip(p_values.keys(),result[1]))\n",
    "    corrected_pvalues[method] = p_valuesC\n",
    "\n",
    "# create a Pandas DataFrame from the corrected p-values\n",
    "df = pd.DataFrame(corrected_pvalues)\n",
    "\n",
    "# set the index to the original p-values (optional)\n",
    "df.index = p_values_list\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to the DataFrame with the promedios dictionary values\n",
    "df['diferencias'] = list(promedios.values())\n",
    "# Reset the index to a new column\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Rename the new index column to something meaningful (e.g., 'original_index')\n",
    "df = df.rename(columns={'index': 'p-value'})\n",
    "count_less_than_005 = (df < 0.05).sum()\n",
    "print(count_less_than_005)\n",
    "\n",
    "df['who'] = list(promedios.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"comparacion.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
