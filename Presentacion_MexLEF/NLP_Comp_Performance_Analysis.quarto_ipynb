{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Analysis of systems’ performance in natural language processing competitions\"\n",
        "author: \"Sergio Nava-Muñoz/ Mario Graff/ Hugo Jair Escalante\"\n",
        "institute:  \"CIMAT / INFOTEC / INAOE\"\n",
        "date: \"Oct 2024\"\n",
        "format: \n",
        "  revealjs:\n",
        "    slide-number: true\n",
        "    theme: default\n",
        "    logo: figs/logo-infotec.jpeg\n",
        "    css: logo.css\n",
        "toc: TRUE\n",
        "toc-depth: 2\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# Introduction\n",
        "\n",
        "---\n",
        "\n",
        "## Challenge {.smaller}\n",
        "\n",
        "![Challenge](figs/scheme.png){#fig-Challenge width=\"600\" height=\"250\"}\n",
        "\n",
        "\n",
        "\n",
        "- Comparison of multiple participants (systems)\n",
        "- Selected performance metrics\n",
        "- A test dataset of fixed size \\( $n$ \\)\n",
        "- A limited number of submissions per participant\n",
        "- The Reference (Gold Standard) is known just for the organizers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Results for VaxxStance Close track - contextual {.smaller}\n",
        "\n",
        "\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"70%\"}\n",
        "| Obs  | Gold Standard | WordUp.01 | ...   | SQYQP.01 |\n",
        "|------|---------------|-----------|-------|----------|\n",
        "| 1    | favor         | favor     | ...   | favor    |\n",
        "| 2    | favor         | favor     | ...   | none     |\n",
        "| 3    | against       | none      | ...   | against  |\n",
        "| 4    | none          | none      | ...   | none     |\n",
        "| ...  | ...           | ...       | ...   | ...      |\n",
        "| $n_{test}$ | none    | favor     | ...   | against  |\n",
        "\n",
        ":  Results for VaxxStance Close track - contextual {#tbl-VaxxStance1 .striped .hover }\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.column width=\"25%\"  .fragment }\n",
        "| System              | Basque  |\n",
        "|---------------------|---------|\n",
        "| WordUp.01           | 0.5734  |\n",
        "| WordUp.02           | 0.5465  |\n",
        "| MultiAztertest.01   | 0.5024  |\n",
        "| SQYQP.01            | 0.4256  |\n",
        "| MultiAztertest.02   | 0.3428  |\n",
        "\n",
        ":  Results using Macro-averaged F1 Score for \"favor\" and \"against\". {#tbl-VaxxStance2 .striped .hover}\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "# Proposed methodology\n",
        "\n",
        "## Bootstrapping {.smaller}\n",
        "\n",
        "In statistics refers to drawing conclusions about a statistics’ sampling distribution by resampling the sample with replacement data as though it were a population with a fixed size \n",
        "\n",
        "![Bootstrapping](figs/bootstrap.png){#fig-bootstrap width=\"600\" height=\"300\"}\n",
        "\n",
        "\n",
        "## Comparison of Classifiers {.smaller}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "|                | LCI    | Score   | UCI    |        |                | LCI    | Score   | UCI    |\n",
        "|----------------|--------|--------|--------|--------|----------------|--------|--------|--------|\n",
        "| **Basque**     |        |        |        |        | **Spanish**    |        |        |        |\n",
        "| **WordUp.01**  | 0.5031 | 0.5716 | 0.6401 |        | **WordUp.02**  | 0.7734 | 0.8086 | 0.8437 |\n",
        "| WordUp.02      | 0.4751 | 0.5444 | 0.6138 |        | WordUp.01      | 0.7537 | 0.7899 | 0.8261 |\n",
        "| **MultiAztertest.01** | 0.4287 | 0.5007 | 0.5726 |        | **MultiAztertest.01** | 0.6987 | 0.7400 | 0.7814 |\n",
        "| SQYQP.01       | 0.3497 | 0.4237 | 0.4976 |        | SQYQP.01       | 0.6310 | 0.6730 | 0.7149 |\n",
        "| **MultiAztertest.02** | 0.2664 | 0.3402 | 0.4139 |        | **MultiAztertest.02** | 0.5945 | 0.6391 | 0.6837 |\n",
        "\n",
        "\n",
        ":  Results Table for Basque and Spanish {#tbl-independent .striped .hover}\n",
        "\n",
        "\n",
        "![Independent Samples](figs/ordenado2.png){#fig-independent-samples width=\"600\" height=\"300\"}\n",
        "\n",
        "---\n",
        "\n",
        "##   {.smaller}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "|                | LCI    | Diff   | UCI    |        |                | LCI    | Diff   | UCI    |\n",
        "|----------------|--------|--------|--------|--------|----------------|--------|--------|--------|\n",
        "| **Basque (WordUp.01)** |        |        |        |        | **Spanish (WordUp.02)** |        |        |        |\n",
        "| **WordUp.02**  | -0.0371| 0.0269 | 0.0910 |        | **WordUp.01**  | -0.0120| 0.0184 | 0.0488 |\n",
        "| MultiAztertest.01 | -0.0152| 0.0713 | 0.1578 |        | MultiAztertest.01 | 0.0211 | 0.0680 | 0.1149 |\n",
        "| **SQYQP.01**   | 0.0543 | 0.1485 | 0.2427 |        | **SQYQP.01**   | 0.0877 | 0.1351 | 0.1825 |\n",
        "| MultiAztertest.02 | 0.1405 | 0.2314 | 0.3222 |        | MultiAztertest.02 | 0.1165 | 0.1687 | 0.2210 |\n",
        "\n",
        ":  Results Table for Basque (WordUp.01) and Spanish (WordUp.02) {#tbl-Paired .striped .hover}\n",
        "\n",
        "![Paired Samples](figs/mejorordenado2.png){#fig-paired-samples width=\"600\" height=\"300\"}\n",
        "\n",
        "## Hypothesis Testing {.smaller}\n",
        "\n",
        "\n",
        "::: footer\n",
        "*Note: † p<.1, * p<.05, ** p<.1, and *** p<.001.*\n",
        ":::\n",
        "\n",
        "\n",
        "|                     | WordUp.01  | WordUp.02  | MultiAztertest.01 | SQYQP.01  |\n",
        "|---------------------|------------|------------|-------------------|-----------|\n",
        "| **WordUp.02**        | 0.027      |            |                   |           |\n",
        "| MultiAztertest.01    | 0.071 †    | 0.044      |                   |           |\n",
        "| **SQYQP.01**         | 0.148 ***  | 0.121 **   | 0.077 *           |           |\n",
        "| MultiAztertest.02    | 0.231 ***  | 0.204 ***  | 0.160 ***         | 0.083 *   |\n",
        "\n",
        "\n",
        ":  Differences of F₁ score for Basque {#tbl-Basque .striped .hover}\n",
        "\n",
        "![histogram of differences ](figs/histogram2.png){#fig-histogram width=\"600\" height=\"250\"}\n",
        "\n",
        "## Multiple Testing {.smaller}\n",
        "\n",
        "### Risk of Multiple Testing\n",
        "\n",
        "::: {.callout-note}\n",
        "Multiple hypothesis testing increases the risk of Type I errors—the false rejection of a true null hypothesis.\n",
        ":::\n",
        "\n",
        "### Correction Methods {.smaller}\n",
        "\n",
        "\n",
        "- **Bonferroni correction**: Divides the significance level by the number of comparisons.\n",
        "- **Holm's step-down procedure**: Adjusts p-values sequentially.\n",
        "- **Benjamini-Hochberg (BH) procedure**: Controls the false discovery rate (FDR).\n",
        "\n",
        "---\n",
        "\n",
        "## {.smaller}\n",
        "\n",
        "**Estimated p-values for F1 difference **\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "|                   |                   | Difference | $p-value$  | Bonferroni | Holm     | BH       |\n",
        "|-------------------|-------------------|------------|----------|------------|----------|----------|\n",
        "| WordUp.01         | WordUp.02          | 0.027      | **0.2030** | **0.8120** | **0.2030** | **0.2030** |\n",
        "| WordUp.01         | MultiAztertest.01  | 0.071      | **0.0551** | **0.2204** | **0.1102** | **0.0735** |\n",
        "| WordUp.01         | SQYQP.01           | 0.148      | 0.0012   | 0.0048     | 0.0036   | 0.0024   |\n",
        "| WordUp.01         | MultiAztertest.02  | 0.231      | 0.0000   | 0.0000     | 0.0000   | 0.0000   |\n",
        "| WordUp.02         | MultiAztertest.01  | 0.044      | **0.1490** | **0.4470** | **0.1490** | **0.1490** |\n",
        "| WordUp.02         | SQYQP.01           | 0.121      | 0.0039   | 0.0117     | 0.0078   | 0.0058   |\n",
        "| WordUp.02         | MultiAztertest.02  | 0.204      | 0.0000   | 0.0000     | 0.0000   | 0.0000   |\n",
        "| MultiAztertest.01 | SQYQP.01           | 0.077      | 0.0330   | **0.0660** | 0.0330   | 0.0330   |\n",
        "| MultiAztertest.01 | MultiAztertest.02  | 0.160      | 0.0003   | 0.0006     | 0.0006   | 0.0006   |\n",
        "| SQYQP.01          | MultiAztertest.02  | 0.083      | 0.0427   | 0.0427     | 0.0427   | 0.0427   |\n",
        "\n",
        ": Estimated p-value for the F₁ difference without adjustment and with Bonferroni, FDR, Holm, and BH adjustments. {#tbl-p-values  .striped .hover}\n",
        "\n",
        "# Analysed Competitions\n",
        "\n",
        "## Analysis of NLP Competitions  {.smaller .scrollable transition=\"slide\"}\n",
        "\n",
        "\n",
        "\n",
        "| Competition        | Subtask / Language                                       | Metric Used                              | Data Considered                          |\n",
        "|--------------------|----------------------------------------------------------|------------------------------------------|------------------------------------------|\n",
        "| MEX-A3T 2019       | Author Profiling (Spanish, text and images)               | Macro-averaged F1 Score                  | All participants                         |\n",
        "|                    | Aggressiveness Detection (Spanish)                       | F1 Score                                 | All participants                         |\n",
        "| TASS 2020          | General Polarity (Spanish)                               | Macro-averaged F1 Score                  | All participants (Best Runs)             |\n",
        "| **VaxxStance 2021**| **Stance Detection (Basque, Spanish)**                   | **Macro-averaged F1 Score for \"favor\" and \"against\"** | **All participants** |\n",
        "| EXIST 2021         | Sexism Identification (English, Spanish)                 | Accuracy                                 | Top 10 for each language (Best Runs)     |\n",
        "|                    | Sexism Categorization (English, Spanish)                 | Macro-averaged F1 Score                  | Top 10 for each language (Best Runs)     |\n",
        "| DETOXIS 2021       | Toxicity Detection (Spanish)                             | F1 Score                                 | All participants (Best Runs)             |\n",
        "| MeOffendEs 2021    | Offensive Language Identification (Mexican Spanish)      | F1 Score (offensive class)               | All participants (Best Runs)             |\n",
        "| REST-MEX 2021      | Recommendation System (Mexican Spanish)                  | MAE                                      | All participants (baseline)              |\n",
        "|                    | Sentiment Analysis (Mexican Spanish)                     | MAE                                      | All participants (baseline)              |\n",
        "| REST-MEX 2022      | Sentiment Analysis (Mexican Spanish)                     | $Measure_S$                                | All participants (majority class)        |\n",
        "|                    | Epidemiological Semaphore (Mexican Spanish)              | $Measure_C$                                | All participants (majority class)        |\n",
        "| PAR-MEX 2022       | Paraphrase Identification (Mexican Spanish)              | F1 Score                                 | All participants (Best Runs)             |\n",
        "\n",
        ":  Table Metrics and data considered across various competitions {#tbl-Competitions .striped .hover}\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Results for the Various Challenges {.smaller .scrollable transition=\"slide\"}\n",
        "\n",
        "\n",
        "\n",
        "| Challenge          | DETOXIS 2021 | PAR-MEX 2022 | MeOffendEs 2021 | MEX-A3T 2019 (Agg) | MEX-A3T 2019 (author profiling) |\n",
        "|--------------------|--------------|--------------|-----------------|-------------------|--------------------------------|\n",
        "| **Task**           | Toxicity detection | Paraphrase Identification | Non-contextual | Aggressiveness Detection | Author Profiling |\n",
        "| **Metric**         | F1 score     | F1 score     | F1 score        | F1 score          | Macro-averaged F1 score       |\n",
        "| **$n$**            | 891          | 2821         | 2182            | 3156              | 1500                          |\n",
        "| **$m$**            | 31           | 8            | 10              | 25                | 4                             |\n",
        "| **Ties w/ win.**   | 0/3/0/0      | 1/1/1/1      | 1/2/2/1         | 3/7/4/3           | 1/1/1/1                       |\n",
        "| **Poss. compars.** | 465          | 28           | 45              | 300               | 6                             |\n",
        "| **none/Bonf.**     | 80/135       | 6/6          | 7/9             | 70/91             | 2/2                           |\n",
        "| **Holm/BH**        | 112/85       | 6/6          | 8/7             | 80/63             | 2/2                           |\n",
        "| **$|win.-med|$**   | 0.223        | 0.061        | 0.078           | 0.098             | 0.164                         |\n",
        "| **$CV$**           | 42.600       | 4.722        | 16.070          | 19.620            | 46.491                        |\n",
        "| **PPI**            | 35.390       | 5.758        | 28.46           | 52.038            | 42.581                        |\n",
        "\n",
        ":  Results for the Various Challenges {#tbl-Results .striped .hover}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Some Examples {.smaller .scrollable transition=\"slide\"}\n",
        "\n",
        "::: panel-tabset\n",
        "### MeOffendEs subtask3\n"
      ],
      "id": "c0743e13"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| label: fig-MeOffendEs\n",
        "#| fig-cap: Confidence intervals\n",
        "#| fig-alt: Confidence intervals\n",
        "import pickle\n",
        "from CompStats import plot_performance_multiple, plot_difference_multiple, difference_multiple\n",
        "# Recuperar el objeto del archivo\n",
        "with open(\"datos/MeOffendEs_subtask3.dat\", \"rb\") as archivo:\n",
        "    perf = pickle.load(archivo)\n",
        "\n",
        "face_grid = plot_performance_multiple(perf)\n",
        "diff = difference_multiple(perf) \n",
        "face_grid_diff = plot_difference_multiple(diff)"
      ],
      "id": "fig-MeOffendEs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DETOXIS 2021\n"
      ],
      "id": "69e2341a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| label: fig-detoxis\n",
        "#| fig-cap: Confidence intervals\n",
        "#| fig-alt: Confidence intervals\n",
        "\n",
        "import pickle\n",
        "from CompStats import plot_performance_multiple, plot_difference_multiple, difference_multiple\n",
        "# Recuperar el objeto del archivo\n",
        "with open(\"datos/detoxis_subtask1.dat\", \"rb\") as archivo:\n",
        "    perf = pickle.load(archivo)\n",
        "\n",
        "face_grid = plot_performance_multiple(perf)\n",
        "diff = difference_multiple(perf) \n",
        "face_grid_diff = plot_difference_multiple(diff)"
      ],
      "id": "fig-detoxis",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  PAR-MEX 2022\n"
      ],
      "id": "540c0fb6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| label: fig-parmex\n",
        "#| fig-cap: Confidence intervals\n",
        "#| fig-alt: Confidence intervals\n",
        "\n",
        "import pickle\n",
        "from CompStats import plot_performance_multiple, plot_difference_multiple, difference_multiple\n",
        "# Recuperar el objeto del archivo\n",
        "with open(\"datos/PARMEX_2022.dat\", \"rb\") as archivo:\n",
        "    perf = pickle.load(archivo)\n",
        "\n",
        "face_grid = plot_performance_multiple(perf)\n",
        "diff = difference_multiple(perf) \n",
        "face_grid_diff = plot_difference_multiple(diff)"
      ],
      "id": "fig-parmex",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  BoW\n",
        "\n",
        "\n",
        "![Confidence Intervals](figs/IC.png){#fig-BoW-IC width=\"300\" height=\"300\"}\n",
        "\n",
        "![Confidence Intervals of Differences](figs/ICD.png){#fig-BoW-ICD width=\"300\" height=\"300\"}\n",
        "\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "## CompStats {.smaller .scrollable transition=\"slide\"}\n",
        "\n",
        "\n",
        "The package _CompStats_ [(compstats.readthedocs.org)](http://compstats.readthedocs.org) implements the ideas presented in this contribution.\n",
        "\n",
        "### Installation\n",
        "\n",
        "```python\n",
        "pip install CompStats\n",
        "```\n",
        "### libraries\n",
        "Once CompStats is installed, one must load a few libraries.\n"
      ],
      "id": "b9212cd1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "from CompStats import performance, difference, plot_performance, plot_difference, difference_p_value\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "from sklearn.metrics import f1_score\n",
        "import pandas as pd"
      ],
      "id": "a51afc7d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data\n",
        "Let us assume *PARMEX_2022.csv* is a csv file where the column $y$ has the ground truth, and the other columns are the systems'outputs.\n"
      ],
      "id": "8c01a958"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "DATA = 'PARMEX_2022.csv'\n",
        "df = pd.read_csv(DATA)"
      ],
      "id": "7ed7e2ae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The performance metric used is the F1 score.\n",
        "\n",
        "\n",
        "\n",
        "### Metric"
      ],
      "id": "c99ffaa9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "score = lambda y, hy: f1_score(y, hy)"
      ],
      "id": "8f04e384",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Performance"
      ],
      "id": "178e9061"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "perf = performance(df, score=score)\n",
        "ins = plot_performance(perf)"
      ],
      "id": "67f37d21",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Performance Differences Against the Winner"
      ],
      "id": "c88248d9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "diff = difference(perf)\n",
        "ins = plot_difference(diff)"
      ],
      "id": "955e4b0e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Performance Differences Against the Winner"
      ],
      "id": "372f1e2d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "p_values = difference_p_value(diff)\n",
        "p_values"
      ],
      "id": "15bbf05d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bonferroni Correction"
      ],
      "id": "67653cd5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "result = multipletests(list(p_values.values()), method='bonferroni')\n",
        "p_valuesC = dict(zip(p_values.keys(), result[1]))\n",
        "p_valuesC"
      ],
      "id": "ada6de2e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary of Research\n",
        "- **Objectives**: \n",
        "  - Analyze existing methodologies for comparing algorithms.\n",
        "  - Develop a framework for evaluating algorithmic performance.\n",
        "  - Validate framework in real-world competitions.\n",
        "  \n",
        "- **Key Findings**:\n",
        "  - Statistical tests like Wilcoxon and Friedman are effective.\n",
        "  - Introduced tools for fair competition result comparison.\n",
        "  - Developed a structured evaluation framework for competitions.\n",
        "\n",
        "---\n",
        "\n",
        "## Contributions to Knowledge\n",
        "- **Theoretical**:\n",
        "  - Formalization of competition-based algorithm evaluation.\n",
        "  - Expanded understanding of statistical tests and competition comparison.\n",
        "\n",
        "- **Practical**:\n",
        "  - Toolkit for statistical evaluation.\n",
        "  - Actionable feedback for participants in algorithmic competitions.\n",
        "\n",
        "---\n",
        "\n",
        "## Limitations and Future Work\n",
        "- **Limitations**:\n",
        "  - Data availability and external validity.\n",
        "  - Focus on classification competitions.\n",
        "  \n",
        "- **Future Work**:\n",
        "  - Expand to other competition types (e.g., regression).\n",
        "  - Develop refined evaluation metrics.\n",
        "  - Integrate statistical tools in a more consistent manner.\n",
        "\n",
        "---"
      ],
      "id": "1be8e9ec"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\Sergio Nava\\AppData\\Roaming\\Python\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}