{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Analysis of systems’ performance in natural language processing competitions\"\n",
        "author: \"Sergio M. Nava Muñoz\"\n",
        "institute:  \"CIMAT / INFOTEC\"\n",
        "date: \"Oct 2024\"\n",
        "format:  html\n",
        "---\n",
        "\n",
        "\n",
        "# Table of Contents\n",
        "- Introduction\n",
        "- Challenge\n",
        "- Comparative Analysis\n",
        "- Performance Evaluation\n",
        "- Conclusion\n",
        "\n",
        "## Introduction\n",
        "\n",
        "### Challenge\n",
        "\n",
        "![Challenge](figs/Competencia.png)\n",
        "\n",
        "## Challenge Restrictions\n",
        "\n",
        "::: {.callout-note}\n",
        "- Comparison of multiple participants (systems)\n",
        "- Selected performance metrics\n",
        "- A test dataset of fixed size \\( n \\)\n",
        "- A limited number of submissions per participant\n",
        "- The Reference (Gold Standard) is known just for the organizers\n",
        "- The objective can be to choose the best or to rank the participants\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "## Results for VaxxStance Close track - contextual {.smaller}\n",
        "\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"70%\"}\n",
        "| Obs  | Gold Standard | WordUp.01 | ...   | SQYQP.01 |\n",
        "|------|---------------|-----------|-------|----------|\n",
        "| 1    | favor         | favor     | ...   | favor    |\n",
        "| 2    | favor         | favor     | ...   | none     |\n",
        "| 3    | against       | none      | ...   | against  |\n",
        "| 4    | none          | none      | ...   | none     |\n",
        "| ...  | ...           | ...       | ...   | ...      |\n",
        "| \\(n_{test}\\) | none    | favor     | ...   | against  |\n",
        "\n",
        "*Table: Results for VaxxStance Close track - contextual.*\n",
        ":::\n",
        "\n",
        "::: {.column width=\"25%\"}\n",
        "| System              | Basque  |\n",
        "|---------------------|---------|\n",
        "| WordUp.01           | 0.5734  |\n",
        "| WordUp.02           | 0.5465  |\n",
        "| MultiAztertest.01    | 0.5024  |\n",
        "| SQYQP.01            | 0.4256  |\n",
        "| MultiAztertest.02    | 0.3428  |\n",
        "\n",
        "*Table: Results using Macro-averaged F1 Score for \"favor\" and \"against\".*\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "\n",
        "## Competition Metrics and Data Considered {.smaller}\n",
        "\n",
        "\n",
        ":::{.small-table}\n",
        "| Competition        | Subtask / Language                                       | Metric Used                              | Data Considered                          |\n",
        "|--------------------|----------------------------------------------------------|------------------------------------------|------------------------------------------|\n",
        "| MEX-A3T 2019       | Author Profiling (Spanish, text and images)               | Macro-averaged F1 Score                  | All participants                         |\n",
        "|                    | Aggressiveness Detection (Spanish)                       | F1 Score                                 | All participants                         |\n",
        "| TASS 2020          | General Polarity (Spanish)                               | Macro-averaged F1 Score                  | All participants (Best Runs)             |\n",
        "| **VaxxStance 2021**| **Stance Detection (Basque, Spanish)**                   | **Macro-averaged F1 Score for \"favor\" and \"against\"** | **All participants** |\n",
        "| EXIST 2021         | Sexism Identification (English, Spanish)                 | Accuracy                                 | Top 10 for each language (Best Runs)     |\n",
        "|                    | Sexism Categorization (English, Spanish)                 | Macro-averaged F1 Score                  | Top 10 for each language (Best Runs)     |\n",
        "| DETOXIS 2021       | Toxicity Detection (Spanish)                             | F1 Score                                 | All participants (Best Runs)             |\n",
        "| MeOffendEs 2021    | Offensive Language Identification (Mexican Spanish)      | F1 Score (offensive class)               | All participants (Best Runs)             |\n",
        "| REST-MEX 2021      | Recommendation System (Mexican Spanish)                  | MAE                                      | All participants (baseline)              |\n",
        "|                    | Sentiment Analysis (Mexican Spanish)                     | MAE                                      | All participants (baseline)              |\n",
        "| REST-MEX 2022      | Sentiment Analysis (Mexican Spanish)                     | Measure_S                                | All participants (majority class)        |\n",
        "|                    | Epidemiological Semaphore (Mexican Spanish)              | Measure_C                                | All participants (majority class)        |\n",
        "| PAR-MEX 2022       | Paraphrase Identification (Mexican Spanish)              | F1 Score                                 | All participants (Best Runs)             |\n",
        ":::\n",
        "\n",
        "\n",
        "*Table: Metrics and data considered across various competitions.*\n"
      ],
      "id": "e550a151"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "1 + 1"
      ],
      "id": "d3d9e7f5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "1 + 1\n",
        "```\n",
        "\n",
        "*Challenge scheme*\n",
        "\n",
        "\n",
        "## Comparative Analysis\n",
        "\n",
        "### Evaluation Criteria\n",
        "\n",
        "Here you can add a description of the evaluation criteria used in your comparative analysis.\n",
        "\n",
        "---\n",
        "\n",
        "### Results Overview\n",
        "\n",
        "Results and corresponding analysis can be shown here.\n",
        "\n",
        "## Performance Evaluation\n",
        "\n",
        "Details regarding system performance.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "Summarize the key takeaways from your analysis."
      ],
      "id": "eaf01899"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\Sergio Nava\\AppData\\Roaming\\Python\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}